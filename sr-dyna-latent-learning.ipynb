{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SR-Dyna (Latent Learning Task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import srdyna\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'srdyna' from '/Users/jeremygordon/repos/sr-dyna/srdyna.py'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(srdyna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10x10 world with 102 states\n"
     ]
    }
   ],
   "source": [
    "# Latent Learning\n",
    "REPLAY = \"sufficient\"\n",
    "EXPLORE_STEPS = 25000\n",
    "POST_REWARD_STEPS = 20\n",
    "REPLAY_STEPS = {\n",
    "    \"insufficient\": 10,\n",
    "    \"sufficient\": 10000\n",
    "}[REPLAY]\n",
    "env = srdyna.SimpleGridWorld(world='worlds/latent_learning.txt')\n",
    "agent = srdyna.SRDyna(id=0, loc=(0, 2), env=env)\n",
    "\n",
    "# Explore\n",
    "for i in range(EXPLORE_STEPS):\n",
    "    agent.step(random_policy=True)\n",
    "\n",
    "# Add reward\n",
    "R1_LOC = (9, 8)\n",
    "env.add_reward(R_LOC, 10)\n",
    "\n",
    "for i in range(POST_REWARD_STEPS):\n",
    "    # Repeated one-step runs from R1\n",
    "    agent.terminate_episode(reset_state=env.state_at_loc(R1_LOC))\n",
    "    agent.step(verbose=False)\n",
    "\n",
    "agent.make_plots(sr_state=9)\n",
    "\n",
    "# One-step replay samples from random sa's\n",
    "agent.learn_offline(k=REPLAY_STEPS)\n",
    "    \n",
    "agent.make_plots(sr_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = (9, 8)\n",
    "agent.make_plots(sr_state=env.state_at_loc(loc))\n",
    "sa = agent.state_action_index(env.state_at_loc(loc), 0)\n",
    "agent.H[sa, sa:sa+4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate anim (slow)\n",
    "agent.record_trials(title=\"latent_learning\", \n",
    "                    start_locs=[(0, 2), (4, 0), (9, 0), (0, 8)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
